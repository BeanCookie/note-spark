#### 什么是RDD
RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。

#### 如何创建RDD
- 通过并行化方式创建：主要通过编程语言中的集合转换而来
- 通过读取外部数据创建：包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等，当然也可以读取SQL或者NOSQL中的数据。

#### RDD核心属性
- 分区列表
- 分区计算
- RDD之间的依赖关系
- 分区器
- 首选位置

#### RDD编程API
- 转换操作
  主要做的是就是将一个已有的RDD生成另外一个RDD。Transformation具有lazy特性(延迟加载)。Transformation算子的代码不会真正被执行。只有当我们的程序里面遇到一个action算子的时候，代码才会真正的被执行。这种设计让Spark更加有效率地运行。
- 行动操作
  所有的转化操作最后都需要触发行动操作，从而让Spark进行任务调度。