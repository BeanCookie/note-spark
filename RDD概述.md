#### 什么是RDD
RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。

#### 如何创建RDD
- 通过并行化方式创建：主要通过编程语言中的集合转换而来
- 通过读取外部数据创建：包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等，当然也可以读取SQL或者NOSQL中的数据。

#### RDD核心属性
- 分区列表
- 分区计算
- RDD之间的依赖关系
- 分区器
- 首选位置

#### RDD核心特点

- 多维度的弹性
  - 弹性存储: 可以自由的存储在JVM内存或者外部文件系统
  - 弹性容错: 数据丢失后可以自动恢复
  - 弹性分片: 可以按需选择分片方式

- 分区容错
所有RDD都是采用惰性计算，因此分区是逻辑上的分区，只有当需要计算的时候才会读取每个分区的数据。

- 只读
RDD创建之后无法直接更改数据，只有通过转换操作生成新的RDD。

- 依赖
通过转换操作生成的RDD会包含父RDD的依赖信息又称血缘关系，当RDD数据丢失后正是通过依赖信息重新计算数据的。依赖又分为窄依赖和宽依赖，窄依赖就是RDD中的每个分区都是一对一关系，宽依赖则表示子RDD的每个分区数据与父RDD的所有分区都有关系属于多对多关系。

#### RDD编程API
- 转换操作
  主要做的是就是将一个已有的RDD生成另外一个RDD。Transformation具有lazy特性(延迟加载)。Transformation算子的代码不会真正被执行。只有当我们的程序里面遇到一个action算子的时候，代码才会真正的被执行。这种设计让Spark更加有效率地运行。
- 行动操作
  所有的转化操作最后都需要触发行动操作，从而让Spark进行任务调度。